#task mgr config
hadoop.hdfs.default.name=hdfs://192.85.247.104:19000
hdfs.task.folder:/reminder/task
hdfs.crawleditem.folder:/reminder/items
hadoop.job.tracker:192.85.247.104:9001
task.mapper.class:org.cld.datacrawl.hadoop.CrawlTaskMapper
mapreduce.jobhistory.address=192.85.247.104:10020
mapreduce.jobhistory.webapp.address=192.85.247.104:19888
mapreduce.jobhistory.intermediate-done-dir=/mr-history/tmp
mapreduce.jobhistory.done-dir=/mr-history/done
mapred.textoutputformat.separator=,
mapreduce.task.timeout=0
mapreduce.job.split.metainfo.maxsize=-1
mapreduce.map.speculative=false
mapreduce.job.user.classpath.first=true
yarn.scheduler.minimum-allocation-mb=128
dfs.replication=1
yarn.application.classpath=/reminder/lib/
crawl.task.per.mapper=20

#crawl mgr config
use.proxy=true
#houston proxy
proxy.ip=16.85.88.10
proxy.port=8080

#time out for remote request, fetch page, invoke ws request, etc, in second unit
time.out=80

#for crawl
# of timeout retry for each link = retry.num * max.loop * wait.time
retry.num=5
max.loop=10
wait.time=4000

#data store manager: hibernate, hbase
crawl.ds.manager=hbase, hdfs
#hbase-site.xml should be put under class path if using hbase ds manager

#result data manager, crawled to hdfs then loaded to some result data store, like hive, etc
result.dm.driver=org.apache.hive.jdbc.HiveDriver
result.dm.url=jdbc:hive2://192.85.247.104:10000/default
result.dm.user=dbadmin
result.dm.pass=password

#
enable.stat=true
#
#ws.main.url=http://54.187.167.132:8080/crbookws/services/crbookrs #amazon
#ws.main.url=http://localhost:8080/crbookws/services/crbookrs
#
#plugin.jar=/data/reminder/lib/cld-shopping-1.0.0.jar

#product definition
product.type=default
default.entity.impl=org.cld.datastore.entity.Product
default.handler.impl=org.cld.pagea.general.DefaultHandler

#task type definition
task.type=org.cld.datacrawl.task.BrowseCategoryTaskConf,org.cld.datacrawl.task.BrowseDetailTaskConf,org.cld.datacrawl.task.BrowseProductTaskConf,org.cld.datacrawl.task.TestTaskConf,org.cld.datacrawl.task.InvokeTaskTaskConf

org.cld.datacrawl.task.BrowseCategoryTaskConf.entity=org.cld.datacrawl.task.BrowseCategoryTaskConf
org.cld.datacrawl.task.BrowseCategoryTaskConf.stat=org.cld.datacrawl.task.BrsCatStat

org.cld.datacrawl.task.BrowseDetailTaskConf.entity=org.cld.datacrawl.task.BrowseDetailTaskConf
org.cld.datacrawl.task.BrowseDetailTaskConf.stat=org.cld.datacrawl.task.BrsDetailStat

org.cld.datacrawl.task.BrowseProductTaskConf.entity=org.cld.datacrawl.task.BrowseProductTaskConf
org.cld.datacrawl.task.BrowseProductTaskConf.stat=org.cld.taskmgr.entity.TaskStat

org.cld.datacrawl.task.TestTaskConf.entity=org.cld.datacrawl.task.TestTaskConf
org.cld.datacrawl.task.TestTaskConf.stat=org.cld.taskmgr.entity.TaskStat

org.cld.datacrawl.task.InvokeTaskTaskConf.entity=org.cld.datacrawl.task.InvokeTaskTaskConf
org.cld.datacrawl.task.InvokeTaskTaskConf.stat=org.cld.taskmgr.entity.TaskStat

#crawl task conf
crawl.taskconf=general

general.category.impl=org.cld.pagea.general.CategoryAnalyze
general.list.impl=org.cld.pagea.general.ListAnalyze
general.product.list.impl=org.cld.pagea.general.ProductListAnalyze
general.prom.detail.impl=org.cld.crbook.util.EmptyPromotionAnalyze
general.product.detail.impl=org.cld.pagea.general.ProductAnalyze

#task definitions
task.name=